{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97IkZKXA0TcL"
      },
      "source": [
        "# Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv7KCVjez2OX",
        "outputId": "c94e4723-f271-48bf-d35d-7c15e2918c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting PyYAML>=5.3 (from langchain)\n",
            "  Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.28-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Using cached aiohttp-3.9.3-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting langchain-core<0.2,>=0.1.29 (from langchain)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting numpy<2,>=1 (from langchain)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Collecting pydantic<3,>=1 (from langchain)\n",
            "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Collecting anyio<5,>=3 (from langchain-core<0.2,>=0.1.29->langchain)\n",
            "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Using cached orjson-3.9.15-cp312-none-win_amd64.whl.metadata (50 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
            "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain)\n",
            "  Using cached pydantic_core-2.16.3-cp312-none-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
            "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
            "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
            "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
            "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "   ---------------------------------------- 0.0/807.5 kB ? eta -:--:--\n",
            "   - -------------------------------------- 30.7/807.5 kB 1.3 MB/s eta 0:00:01\n",
            "   ----- ---------------------------------- 112.6/807.5 kB 1.3 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 225.3/807.5 kB 1.5 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 368.6/807.5 kB 1.9 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 583.7/807.5 kB 2.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 807.5/807.5 kB 3.2 MB/s eta 0:00:00\n",
            "Using cached aiohttp-3.9.3-cp312-cp312-win_amd64.whl (363 kB)\n",
            "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.5/1.8 MB 15.4 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 0.7/1.8 MB 9.1 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 1.4/1.8 MB 9.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 1.6/1.8 MB 8.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.8/1.8 MB 8.0 MB/s eta 0:00:00\n",
            "Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "   ---------------------------------------- 0.0/256.9 kB ? eta -:--:--\n",
            "   --------------------------------------- 256.9/256.9 kB 16.4 MB/s eta 0:00:00\n",
            "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Downloading langsmith-0.1.22-py3-none-any.whl (66 kB)\n",
            "   ---------------------------------------- 0.0/66.6 kB ? eta -:--:--\n",
            "   ---------------------------------------- 66.6/66.6 kB 3.5 MB/s eta 0:00:00\n",
            "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "Using cached pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
            "Using cached pydantic_core-2.16.3-cp312-none-win_amd64.whl (1.9 MB)\n",
            "Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
            "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Downloading SQLAlchemy-2.0.28-cp312-cp312-win_amd64.whl (2.1 MB)\n",
            "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
            "   ------------ --------------------------- 0.6/2.1 MB 19.8 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.1/2.1 MB 13.5 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.5/2.1 MB 11.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.0/2.1 MB 11.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.1/2.1 MB 11.0 MB/s eta 0:00:00\n",
            "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
            "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
            "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
            "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
            "   ---------------------------------------- 0.0/293.6 kB ? eta -:--:--\n",
            "   --------------------------------------- 293.6/293.6 kB 17.7 MB/s eta 0:00:00\n",
            "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
            "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 49.4/49.4 kB ? eta 0:00:00\n",
            "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
            "Using cached orjson-3.9.15-cp312-none-win_amd64.whl (136 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpatch, idna, greenlet, frozenlist, charset-normalizer, certifi, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic, anyio, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 certifi-2024.2.2 charset-normalizer-3.3.2 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 idna-3.6 jsonpatch-1.33 langchain-0.1.11 langchain-community-0.0.27 langchain-core-0.1.30 langchain-text-splitters-0.0.1 langsmith-0.1.22 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.9.15 pydantic-2.6.3 pydantic-core-2.16.3 requests-2.31.0 sniffio-1.3.1 tenacity-8.2.3 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyterlab-server 2.25.3 requires jinja2>=3.0.3, which is not installed.\n",
            "jupyter-server 2.12.5 requires jinja2, which is not installed.\n",
            "qiskit-terra 0.45.2 requires ply>=3.10, which is not installed.\n",
            "qiskit-terra 0.45.2 requires sympy>=1.3, which is not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from huggingface_hub)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
            "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface_hub) (2.31.0)\n",
            "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
            "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface_hub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "   ---------------------------------------- 0.0/346.4 kB ? eta -:--:--\n",
            "   - -------------------------------------- 10.2/346.4 kB ? eta -:--:--\n",
            "   ---- ---------------------------------- 41.0/346.4 kB 495.5 kB/s eta 0:00:01\n",
            "   ------ -------------------------------- 61.4/346.4 kB 656.4 kB/s eta 0:00:01\n",
            "   ---------------- --------------------- 153.6/346.4 kB 919.0 kB/s eta 0:00:01\n",
            "   ------------------------------- -------- 276.5/346.4 kB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 346.4/346.4 kB 1.5 MB/s eta 0:00:00\n",
            "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: tqdm, fsspec, filelock, huggingface_hub\n",
            "Successfully installed filelock-3.13.1 fsspec-2024.2.0 huggingface_hub-0.21.4 tqdm-4.66.2\n",
            "Collecting sentence_transformers\n",
            "  Using cached sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting transformers<5.0.0,>=4.32.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "     ---------------------------------------- 0.0/130.7 kB ? eta -:--:--\n",
            "     ----- ------------------------------- 20.5/130.7 kB 330.3 kB/s eta 0:00:01\n",
            "     ----------------- ------------------- 61.4/130.7 kB 544.7 kB/s eta 0:00:01\n",
            "     ------------------------------------ 130.7/130.7 kB 963.3 kB/s eta 0:00:00\n",
            "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sentence_transformers) (4.66.2)\n",
            "Collecting torch>=1.11.0 (from sentence_transformers)\n",
            "  Using cached torch-2.2.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sentence_transformers) (1.26.4)\n",
            "Collecting scikit-learn (from sentence_transformers)\n",
            "  Using cached scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sentence_transformers) (1.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sentence_transformers) (0.21.4)\n",
            "Collecting Pillow (from sentence_transformers)\n",
            "  Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Collecting sympy (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.32.0->sentence_transformers)\n",
            "  Using cached regex-2023.12.25-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.32.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.15.2-cp312-none-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.32.0->sentence_transformers)\n",
            "  Using cached safetensors-0.4.2-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
            "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
            "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Collecting mpmath>=0.19 (from sympy->torch>=1.11.0->sentence_transformers)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "Using cached torch-2.2.1-cp312-cp312-win_amd64.whl (198.5 MB)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.1/8.5 MB 4.3 MB/s eta 0:00:02\n",
            "    --------------------------------------- 0.2/8.5 MB 2.5 MB/s eta 0:00:04\n",
            "   - -------------------------------------- 0.3/8.5 MB 2.8 MB/s eta 0:00:03\n",
            "   - -------------------------------------- 0.4/8.5 MB 2.5 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 0.5/8.5 MB 2.4 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 0.7/8.5 MB 2.5 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 0.8/8.5 MB 2.6 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 0.9/8.5 MB 2.6 MB/s eta 0:00:03\n",
            "   ---- ----------------------------------- 1.0/8.5 MB 2.5 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 1.2/8.5 MB 2.7 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 1.2/8.5 MB 2.6 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 1.3/8.5 MB 2.4 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 1.5/8.5 MB 2.5 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 1.7/8.5 MB 2.7 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 1.8/8.5 MB 2.7 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 2.1/8.5 MB 2.9 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 2.3/8.5 MB 2.9 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 2.3/8.5 MB 2.9 MB/s eta 0:00:03\n",
            "   ----------- ---------------------------- 2.5/8.5 MB 2.8 MB/s eta 0:00:03\n",
            "   ------------ --------------------------- 2.8/8.5 MB 3.0 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 3.0/8.5 MB 3.1 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 3.3/8.5 MB 3.2 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 3.6/8.5 MB 3.4 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 3.9/8.5 MB 3.5 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 4.1/8.5 MB 3.5 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 4.3/8.5 MB 3.6 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 4.3/8.5 MB 3.5 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 4.6/8.5 MB 3.5 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 4.9/8.5 MB 3.6 MB/s eta 0:00:02\n",
            "   ----------------------- ---------------- 5.0/8.5 MB 3.6 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 5.2/8.5 MB 3.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 5.4/8.5 MB 3.7 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 5.6/8.5 MB 3.7 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 5.7/8.5 MB 3.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 5.9/8.5 MB 3.7 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 6.1/8.5 MB 3.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 6.3/8.5 MB 3.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.7/8.5 MB 3.8 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.8/8.5 MB 3.8 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 7.2/8.5 MB 3.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 7.6/8.5 MB 4.0 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 8.1/8.5 MB 4.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  8.5/8.5 MB 4.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.5/8.5 MB 4.2 MB/s eta 0:00:00\n",
            "Downloading pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
            "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 0.5/2.6 MB 10.9 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 1.0/2.6 MB 12.2 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.5/2.6 MB 12.0 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 2.2/2.6 MB 11.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 2.5/2.6 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.6/2.6 MB 9.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.6/2.6 MB 9.3 MB/s eta 0:00:00\n",
            "Using cached scikit_learn-1.4.1.post1-cp312-cp312-win_amd64.whl (10.6 MB)\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Using cached regex-2023.12.25-cp312-cp312-win_amd64.whl (268 kB)\n",
            "Using cached safetensors-0.4.2-cp312-none-win_amd64.whl (270 kB)\n",
            "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Downloading tokenizers-0.15.2-cp312-none-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 0.3/2.2 MB 9.6 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 0.7/2.2 MB 8.9 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 1.1/2.2 MB 8.4 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.1/2.2 MB 6.5 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 1.5/2.2 MB 7.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 1.9/2.2 MB 7.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 6.9 MB/s eta 0:00:00\n",
            "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: mpmath, threadpoolctl, sympy, safetensors, regex, Pillow, networkx, MarkupSafe, joblib, scikit-learn, jinja2, torch, tokenizers, transformers, sentence_transformers\n",
            "Successfully installed MarkupSafe-2.1.5 Pillow-10.2.0 jinja2-3.1.3 joblib-1.3.2 mpmath-1.3.0 networkx-3.2.1 regex-2023.12.25 safetensors-0.4.2 scikit-learn-1.4.1.post1 sentence_transformers-2.5.1 sympy-1.12 threadpoolctl-3.3.0 tokenizers-0.15.2 torch-2.2.1 transformers-4.38.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyterlab 4.1.2 requires httpx>=0.25.0, which is not installed.\n",
            "nbconvert 7.16.1 requires beautifulsoup4, which is not installed.\n",
            "qiskit-terra 0.45.2 requires ply>=3.10, which is not installed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting accelerate\n",
            "  Using cached accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (2.2.1)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from bitsandbytes) (1.12.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "Installing collected packages: bitsandbytes, accelerate\n",
            "Successfully installed accelerate-0.27.2 bitsandbytes-0.42.0\n",
            "Requirement already satisfied: accelerate in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (2.2.1)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install huggingface_hub\n",
        "!pip install sentence_transformers\n",
        "!pip install accelerate bitsandbytes\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12xoPq050x4X"
      },
      "source": [
        "# HuggigFace API Key Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HyNQRzlGz9K7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN']='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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpWEXDuk02Pf"
      },
      "source": [
        "# Load the Open Source Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (2.2.1)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hp\\anaconda3\\envs\\emotion\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865,
          "referenced_widgets": [
            "7d5b655fdfd546acb896d083ce6faead",
            "0e9c3338e38441e3ab0750395f0f2321",
            "ebb468b66fec4f4c8c94a4cef4d23034",
            "15d57fc0222f4f2a8e590f0e925156f3",
            "233c8e331186427e84f0f66d7d6f1dbb",
            "bb31570c725b40a18488052be2226499",
            "9c43d09f37c246cba59eddaabe718139",
            "db45497ec31a49a998ab09edf7b3ac74",
            "da9818ea260746d0a3fc93ff4a8a95ae",
            "34086edb2e294161b372c0a1ef82116b",
            "97e0215c9c2e438796a5d798153a9b23",
            "ad3d27eafbe147159d9da8f157c0e7f8",
            "15262b3bf42d45b49056bcce155b3e32",
            "0f9c895a37ac4c4684bf26078e4ee1a4",
            "3af044402ef84e51b1035f0e0cb25fd5",
            "66b49cbc53404fd383c85c02725024cb",
            "8fafb2ef234645f18eb4c349c5e9b2be",
            "9b34e45a9fce4fd58133e08165d5a746",
            "31c8e5fb2ada4283b9bbceb08989d516",
            "bd21de1085e547679edcd49f07ecbea0",
            "29a66b9da07b428aac7353ab4be982bc",
            "3f3eb0db41204705a67d5f5260e7eb52",
            "4601bb5dadb14e93ae0010b8697fc788",
            "1764e9c957994b48a4ef71e71d8a1155",
            "245ff5c69b8b49578af2d9de28261256",
            "7da2c280e6af4ff5ad350afca7d5eeb2",
            "aa1782f8f91a4ad2a81c2c426ad5a2ed",
            "8b172b26363c46eb99f3385233daba95",
            "cb5d183793ff4ca8b37ca1383c18c045",
            "ebedf123ec874134b0017a3fd1f4c468",
            "3127fefce38a449190424760c3c3b482",
            "8a80577c0b974e9db3546fc07f729359",
            "a1661f05b7a5434d9c2866715dab7722",
            "e95678826a0449a8a7c5a5523da54f07",
            "d68a2adb91de441d81e20fc84837a646",
            "41e18a1da31343a0b8e3a1f74fc864bd",
            "1e7fcd5d175740d2a919a4b25a501ab4",
            "c561fbc71a89447b9c8068c43ee8f71f",
            "2e2d201d9b9448faaa2eb3bee8917951",
            "6c4ea8d4ab0945d0b8e7a221852d9f3b",
            "768f5387bc2c4bfa87e9c16c0f31bfe1",
            "a57342e1d4ce41578717028f77cd3dd6",
            "9f0743f3659a4b21a7cd87972a06b96e",
            "63035c68698141ffa97c22e453a40909",
            "aa97ed7b1abf47768b338535d6403e97",
            "ddb5aeaf22bc4084bba927cb27bf5f92",
            "f880c2ef5aec43ed8ac431c8b2fcbd8b",
            "a5055030578e491aa72b94d18fcb6ab7",
            "f6a3c5e91a33414b982177b431f1d2e6",
            "2c902c8b214c491d9b3fcbb6a12c60d8",
            "1aa74246f79d49a2a2f37ab83ceddf21",
            "bd93ac4ea2d041219aed2a3fd362e200",
            "563182c9072d453a8b88a9e9da223659",
            "5f8c3d2586a7464fa06585a3453850e9",
            "dcdc8035335f48f6bbf11a8e8e3b22c1"
          ]
        },
        "id": "RzKtDmTo0sdC",
        "outputId": "8f48ac13-bddb-4375-a002-ea84fe5dbbaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\emotion\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\emotion\\Lib\\site-packages\\transformers\\modeling_utils.py:3024\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[0;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3027\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3028\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
            "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\emotion\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:62\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_environment\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_bitsandbytes_available()):\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m         )\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m         )\n",
            "\u001b[1;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_8bit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwlTMwxK1ibO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256\n",
        "  )\n",
        "\n",
        "local_llm = HuggingFacePipeline(pipeline=pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QufCnaU7Onp"
      },
      "source": [
        "# Language Expression Language (LCEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3TEtQvr520G"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlY1qGCR7s1N"
      },
      "outputs": [],
      "source": [
        "prompt_1 = ChatPromptTemplate.from_template(\"How to prepare {topic}\")\n",
        "model_1= local_llm\n",
        "output_parser_1 = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVF3Vqgt70mn"
      },
      "outputs": [],
      "source": [
        "chain_1 = prompt_1 | model_1 | output_parser_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "byEzK4As76LA",
        "outputId": "3a588cef-6e4a-44a0-ab78-51982a82cd43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n## How to prepare Noodles\\n\\n1. In a large pot, bring water to a boil. Add salt and noodles. Cook until al dente, about 8 minutes. Drain and rinse with cold water.\\n2. In a large skillet, heat oil over medium heat. Add garlic and cook until fragrant, about 1 minute. Add shrimp and cook until pink, about 2 minutes.\\n3. Add noodles, soy sauce, and sesame oil to the skillet. Toss to combine. Serve immediately.\\n\\n## Tips\\n\\n- If you want to make this dish even more flavorful, you can add some chopped green onions or cilantro.\\n- You can also add some chopped peppers or other vegetables to the dish.\\n- If you want to make this dish spicier, you can add some chili flakes or chili sauce.\\n- You can also add some sesame seeds or chopped peanuts to the dish.\\n- If you want to make this dish even more filling, you can add some cooked chicken or tofu.\\n- You can'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_1.invoke({\"topic\": \"Noodles\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2Aiqpzn-wGx"
      },
      "source": [
        "# Prompt Templates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7yI3kbp-1Vo"
      },
      "source": [
        "Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tw_dTKC37-Qr",
        "outputId": "7995cfd7-85d1-49c0-c476-3b714090ad13"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tell me a funny joke about chickens.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PromptTemplate\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Tell me a {adjective} joke about {content}.\"\n",
        ")\n",
        "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxunrWWz_L6z"
      },
      "source": [
        "Chat Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gh7FCuT8_GUL",
        "outputId": "097f40f1-d708-4ed1-a139-53f9291e59b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Human: Translate the text that is delimited by triple backticks into a style that is Italic. text: ```what is your name?```\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ChatPromptTemplate\n",
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "#print the formated promt\n",
        "prompt_template.format(style=\"Italic\", text=\"what is your name?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bB175Uf_UWi"
      },
      "source": [
        "Few-Shot Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSxHnJf9_PeB"
      },
      "outputs": [],
      "source": [
        "#Few shot prompt template\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: How old was Muhammad Ali when he died?\n",
        "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
        "Follow up: How old was Alan Turing when he died?\n",
        "Intermediate answer: Alan Turing was 41 years old when he died.\n",
        "So the final answer is: Muhammad Ali\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"When was the founder of craigslist born?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who was the founder of craigslist?\n",
        "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
        "Follow up: When was Craig Newmark born?\n",
        "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
        "So the final answer is: December 6, 1952\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who was the mother of George Washington?\n",
        "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
        "Follow up: Who was the father of Mary Ball Washington?\n",
        "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
        "So the final answer is: Joseph Ball\n",
        "\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"\"\"\n",
        "Are follow up questions needed here: Yes.\n",
        "Follow up: Who is the director of Jaws?\n",
        "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
        "Follow up: Where is Steven Spielberg from?\n",
        "Intermediate Answer: The United States.\n",
        "Follow up: Who is the director of Casino Royale?\n",
        "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
        "Follow up: Where is Martin Campbell from?\n",
        "Intermediate Answer: New Zealand.\n",
        "So the final answer is: No\n",
        "\"\"\",\n",
        "    },\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbrT5G3B_aRP",
        "outputId": "10da99f1-cae3-45bb-978f-81d7503a8e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create a formatter\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\"\n",
        ")\n",
        "\n",
        "print(example_prompt.format(**examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6CEpCVv_dnt",
        "outputId": "1121ca02-fa2e-4e59-df2b-33a7c85feec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: How old was Muhammad Ali when he died?\n",
            "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
            "Follow up: How old was Alan Turing when he died?\n",
            "Intermediate answer: Alan Turing was 41 years old when he died.\n",
            "So the final answer is: Muhammad Ali\n",
            "\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the founder of craigslist?\n",
            "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
            "Follow up: When was Craig Newmark born?\n",
            "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
            "So the final answer is: December 6, 1952\n",
            "\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who was the mother of George Washington?\n",
            "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
            "Follow up: Who was the father of Mary Ball Washington?\n",
            "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
            "So the final answer is: Joseph Ball\n",
            "\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "\n",
            "Are follow up questions needed here: Yes.\n",
            "Follow up: Who is the director of Jaws?\n",
            "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
            "Follow up: Where is Steven Spielberg from?\n",
            "Intermediate Answer: The United States.\n",
            "Follow up: Who is the director of Casino Royale?\n",
            "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
            "Follow up: Where is Martin Campbell from?\n",
            "Intermediate Answer: New Zealand.\n",
            "So the final answer is: No\n",
            "\n",
            "\n",
            "Question: Who was the father of Mary Ball Washington?\n"
          ]
        }
      ],
      "source": [
        "#feed the question\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Question: {input}\",\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "print(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EkCIuYX_jR-"
      },
      "source": [
        "# Example Selectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZASM7UIv_gQJ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
        "\n",
        "# Examples of a pretend task of creating antonyms.\n",
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"Input: {input}\\nOutput: {output}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AulSe-dz_5WL"
      },
      "outputs": [],
      "source": [
        "example_selector = LengthBasedExampleSelector(\n",
        "    # The examples it has available to choose from.\n",
        "    examples=examples,\n",
        "    # The PromptTemplate being used to format the examples.\n",
        "    example_prompt=example_prompt,\n",
        "    # The maximum length that the formatted examples should be.\n",
        "    max_length=25\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZYnnKML_72_"
      },
      "outputs": [],
      "source": [
        "dynamic_prompt = FewShotPromptTemplate(\n",
        "    # We provide an ExampleSelector instead of examples.\n",
        "    example_selector=example_selector,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Give the antonym of every input\",\n",
        "    suffix=\"Input: {adjective}\\nOutput:\",\n",
        "    input_variables=[\"adjective\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4v_RmMF__DP",
        "outputId": "1eb8d025-eead-4f20-c6ba-92d0a024550a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: tall\n",
            "Output: short\n",
            "\n",
            "Input: energetic\n",
            "Output: lethargic\n",
            "\n",
            "Input: sunny\n",
            "Output: gloomy\n",
            "\n",
            "Input: windy\n",
            "Output: calm\n",
            "\n",
            "Input: big\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "# An example with small input, so it selects all examples.\n",
        "print(dynamic_prompt.format(adjective=\"big\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt3Ew68JABYz",
        "outputId": "6be7081f-d975-4d88-8376-f448b48e63f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give the antonym of every input\n",
            "\n",
            "Input: happy\n",
            "Output: sad\n",
            "\n",
            "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "# An example with long input, so it selects only one example.\n",
        "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
        "print(dynamic_prompt.format(adjective=long_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "302mVxDIAi_v"
      },
      "source": [
        "# Output Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGzMGGykNBPr"
      },
      "source": [
        "CSV Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNpv5NXhAEAD",
        "outputId": "4ccde396-10b6-42d5-9c29-cf9384782837"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['1. Chocolate\\n2. Vanilla\\n3. Strawberry\\n4. Mint Chocolate Chip\\n5. Cookies and Cream\\n\\n### 10. List five things you would do if you were a millionaire.\\n\\n1. Buy a house\\n2. Buy a car\\n3. Buy a boat\\n4. Buy a plane\\n5. Buy a yacht\\n\\n### 11. List five things you would do if you were invisible for a day.\\n\\n1. Go to the White House\\n2. Go to the Vatican\\n3. Go to the Kremlin\\n4. Go to the Great Wall of China\\n5. Go to the Taj Mahal\\n\\n### 12. List five things you would do if you were a genie.\\n\\n1. Grant three wishes\\n2. Make people happy\\n3. Make people rich\\n4. Make people healthy\\n5. Make people wise\\n\\n### 13. List five things you would do if you were a superhero.\\n\\n1. Save the world\\n2. Fight crime\\n3. Stop evil\\n4. Protect the innocent']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "#define the parser type\n",
        "output_parser = CommaSeparatedListOutputParser()\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "#create the template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"List five {subject}.\",\n",
        "    input_variables=[\"subject\"]\n",
        ")\n",
        "\n",
        "_input = prompt.format(subject=\"ice cream flavors\")\n",
        "output = local_llm(_input)\n",
        "output_parser.parse(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkpgWEMPNF_K"
      },
      "source": [
        "Custom Structured Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfqvdwydA0Zi"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "#define the structure\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n",
        "    ResponseSchema(\n",
        "        name=\"source\",\n",
        "        description=\"source used to answer the user's question, should be a website.\",\n",
        "    ),\n",
        "]\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "format_instructions = output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRqHuiHLNx8I"
      },
      "outputs": [],
      "source": [
        "#define the template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
        "    input_variables=[\"question\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NunQ6GSN0sC",
        "outputId": "c96c033f-a821-4319-fdd7-2895283e5950"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'Paris', 'source': 'https://en.wikipedia.org/wiki/Paris'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input = prompt.format(question=\"What is the capital of France?\")\n",
        "output = local_llm(_input)\n",
        "output_parser.parse(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR6vU6aqOdcc"
      },
      "source": [
        "# Document loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyholglMOhRj"
      },
      "source": [
        "CSV Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTb6DBCbN64G"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "\n",
        "\n",
        "loader = CSVLoader(file_path='PASTE-YOUR-FILE-PATH')\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW3jhdhlOnYt"
      },
      "outputs": [],
      "source": [
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38f2HreXOobK"
      },
      "source": [
        "File Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrE0noy_p7B2"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmgORVvkOsC4"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "loader = DirectoryLoader('PASTE-YOUR-FILE-PATH')    #loader = DirectoryLoader('../', glob=\"**/*.md\") -> glob parameter to control which files to load\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAhGAVFbOzP1"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGnN5fbgOzSS"
      },
      "outputs": [],
      "source": [
        "print(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_r-qAedO3kK"
      },
      "source": [
        "PDF Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2zmeYZsOzV8"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy2dcCoPPEMi"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"PASTE-YOUR-FILE-PATH\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0a9iEUGePEOw"
      },
      "outputs": [],
      "source": [
        "pages[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRcU-R8GPReV"
      },
      "source": [
        "# Text Splitters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXEZNlnnPZVe"
      },
      "source": [
        "Split by Character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7Kcpw16PEQ3"
      },
      "outputs": [],
      "source": [
        "data = \"PASTE-YOUR-FILE-PATH\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bus44FVAPEUU"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(data)\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BVRb3u7PfDs"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\\n\",\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTEstVifPfGV"
      },
      "outputs": [],
      "source": [
        "texts = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XieEURZrPfJs"
      },
      "outputs": [],
      "source": [
        "texts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYcgjge3QNLZ"
      },
      "source": [
        "# Text Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KonRk_l13xA-"
      },
      "source": [
        "HuggingFace Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8G5jMUOQb3r"
      },
      "outputs": [],
      "source": [
        "#embeddings\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model = HuggingFaceEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhBeGtuG2oNW"
      },
      "outputs": [],
      "source": [
        "#perform embeddings to the data\n",
        "\n",
        "embeddings = embedding_model.embed_documents(\n",
        "    [\n",
        "        \"Hi there!\",\n",
        "        \"Oh, hello!\",\n",
        "        \"What's your name?\",\n",
        "        \"My friends call me World\",\n",
        "        \"Hello World!\"\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qFJXkG52rE-"
      },
      "outputs": [],
      "source": [
        "len(embeddings), len(embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dsfQ0in2tH8"
      },
      "outputs": [],
      "source": [
        "#perform embedding for the query\n",
        "embedded_query = embedding_model.embed_query(\"What was the name mentioned in the conversation?\")\n",
        "embedded_query[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGLYc3gF3oCu"
      },
      "source": [
        "# Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaGtMKDw3k6G"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9FJ4Rt533no"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "raw_documents = TextLoader('PASTE-YOUR-TEXT-FILE-PATH').load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0) #change values\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "db = FAISS.from_documents(documents, HuggingFaceEmbeddings())  #store in faiss cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkAmqqkO43wh"
      },
      "outputs": [],
      "source": [
        "#perform similarity search\n",
        "\n",
        "query = \"What is AI?\"\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm1567165ip2"
      },
      "source": [
        "# Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIkf3G25IhJ"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NOfuDeL5nkD"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "raw_documents = TextLoader('PASTE-YOUR-TEXT-FILE-PATH').load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0) #change values\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "db = Chroma.from_documents(documents, HuggingFaceEmbeddings())  #store in chroma db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiiM-QMv6IBp"
      },
      "outputs": [],
      "source": [
        "#define the retriever\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRyrvT9c6MWX"
      },
      "outputs": [],
      "source": [
        "#retrive contents\n",
        "docs = retriever.get_relevant_documents(\"Your Query.\")\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jUop-Sa6Vg7"
      },
      "outputs": [],
      "source": [
        "#Similarity score threshold retrieval\n",
        "#You can also set a retrieval method that sets a similarity score threshold and only returns documents with a score above that threshold.\n",
        "\n",
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.5}\n",
        ")\n",
        "\n",
        "docs = retriever.get_relevant_documents(\"Your Query.\")\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmS_tD086uX0"
      },
      "outputs": [],
      "source": [
        "#Specifying top k\n",
        "#you can also specify search kwargs like k to use when doing retrieval.\n",
        "\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 1})\n",
        "\n",
        "docs = retriever.get_relevant_documents(\"Your Query.\")\n",
        "\n",
        "print(\"Length of the documnet : \",len(docs))\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYH88Ohr9SNS"
      },
      "source": [
        "# Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zc8liDE60ea"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkOIxIcZ9XWb"
      },
      "outputs": [],
      "source": [
        "#load the required tool\n",
        "tools = load_tools([\"llm-math\"], llm=local_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znUb-1Gx9cQN"
      },
      "outputs": [],
      "source": [
        "#create the Agent\n",
        "\n",
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    local_llm,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PpYHB9Y9jQz"
      },
      "outputs": [],
      "source": [
        "#run the agent\n",
        "agent(\"What is the 25% of 300?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm5AR3vZ_w8t"
      },
      "source": [
        "# Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unSpCfDm__j4"
      },
      "source": [
        "LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf2-ZoHv-o-Q"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"What is the best name to describe a company that makes {product}?\"\n",
        ")\n",
        "chain = LLMChain(llm=local_llm, prompt=prompt)\n",
        "chain.run(product=\"ice cream\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt2EZt3yAsuw"
      },
      "source": [
        "Simple sequential Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlkjXBxAAagx"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import SimpleSequentialChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygf1E1K3BOqH"
      },
      "outputs": [],
      "source": [
        "# prompt template 1\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name to describe a company that makes {product}?\"\n",
        ")\n",
        "\n",
        "# Chain 1\n",
        "chain_one = LLMChain(llm=local_llm, prompt=first_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtJ59AgFBOsX"
      },
      "outputs": [],
      "source": [
        "# prompt template 2\n",
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a 20 words description for the following company:{company_name}\"\n",
        ")\n",
        "# chain 2\n",
        "chain_two = LLMChain(llm=local_llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0K9ER-mBOvz"
      },
      "outputs": [],
      "source": [
        "#combine all the chain in sequential form\n",
        "\n",
        "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
        "                                             verbose=True\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-O5OcN4BfFR"
      },
      "outputs": [],
      "source": [
        "#run the chain\n",
        "product = \"Perfume\"\n",
        "overall_simple_chain.run(product)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSwgwXoCDXlp"
      },
      "source": [
        "# Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBqnv9buEGKz"
      },
      "source": [
        "ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGQvfX9GCpb6"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# define the llm, memory and chain.\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=local_llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZuyrLijESVF"
      },
      "outputs": [],
      "source": [
        "#start the conversation\n",
        "conversation.predict(input=\"Hi, my name is Ram\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysIyFGJIEVUt"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is 1+1?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqxyYfGAEjSs"
      },
      "outputs": [],
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WadLfEEIEjWN"
      },
      "outputs": [],
      "source": [
        "#print the conversation\n",
        "\n",
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf3IiTmTEqUF"
      },
      "outputs": [],
      "source": [
        "#load the history in the dictionary\n",
        "\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3gLuaozwHgt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e9c3338e38441e3ab0750395f0f2321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb31570c725b40a18488052be2226499",
            "placeholder": "",
            "style": "IPY_MODEL_9c43d09f37c246cba59eddaabe718139",
            "value": "tokenizer_config.json:100%"
          }
        },
        "0f9c895a37ac4c4684bf26078e4ee1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c8e5fb2ada4283b9bbceb08989d516",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd21de1085e547679edcd49f07ecbea0",
            "value": 493443
          }
        },
        "15262b3bf42d45b49056bcce155b3e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fafb2ef234645f18eb4c349c5e9b2be",
            "placeholder": "",
            "style": "IPY_MODEL_9b34e45a9fce4fd58133e08165d5a746",
            "value": "tokenizer.model:100%"
          }
        },
        "15d57fc0222f4f2a8e590f0e925156f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34086edb2e294161b372c0a1ef82116b",
            "placeholder": "",
            "style": "IPY_MODEL_97e0215c9c2e438796a5d798153a9b23",
            "value": "967/967[00:00&lt;00:00,30.9kB/s]"
          }
        },
        "1764e9c957994b48a4ef71e71d8a1155": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b172b26363c46eb99f3385233daba95",
            "placeholder": "",
            "style": "IPY_MODEL_cb5d183793ff4ca8b37ca1383c18c045",
            "value": "tokenizer.json:100%"
          }
        },
        "1aa74246f79d49a2a2f37ab83ceddf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e7fcd5d175740d2a919a4b25a501ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f0743f3659a4b21a7cd87972a06b96e",
            "placeholder": "",
            "style": "IPY_MODEL_63035c68698141ffa97c22e453a40909",
            "value": "72.0/72.0[00:00&lt;00:00,4.41kB/s]"
          }
        },
        "233c8e331186427e84f0f66d7d6f1dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "245ff5c69b8b49578af2d9de28261256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebedf123ec874134b0017a3fd1f4c468",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3127fefce38a449190424760c3c3b482",
            "value": 1795303
          }
        },
        "29a66b9da07b428aac7353ab4be982bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c902c8b214c491d9b3fcbb6a12c60d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2d201d9b9448faaa2eb3bee8917951": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3127fefce38a449190424760c3c3b482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31c8e5fb2ada4283b9bbceb08989d516": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34086edb2e294161b372c0a1ef82116b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3af044402ef84e51b1035f0e0cb25fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a66b9da07b428aac7353ab4be982bc",
            "placeholder": "",
            "style": "IPY_MODEL_3f3eb0db41204705a67d5f5260e7eb52",
            "value": "493k/493k[00:00&lt;00:00,7.12MB/s]"
          }
        },
        "3f3eb0db41204705a67d5f5260e7eb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41e18a1da31343a0b8e3a1f74fc864bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_768f5387bc2c4bfa87e9c16c0f31bfe1",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a57342e1d4ce41578717028f77cd3dd6",
            "value": 72
          }
        },
        "4601bb5dadb14e93ae0010b8697fc788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1764e9c957994b48a4ef71e71d8a1155",
              "IPY_MODEL_245ff5c69b8b49578af2d9de28261256",
              "IPY_MODEL_7da2c280e6af4ff5ad350afca7d5eeb2"
            ],
            "layout": "IPY_MODEL_aa1782f8f91a4ad2a81c2c426ad5a2ed"
          }
        },
        "563182c9072d453a8b88a9e9da223659": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f8c3d2586a7464fa06585a3453850e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63035c68698141ffa97c22e453a40909": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66b49cbc53404fd383c85c02725024cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4ea8d4ab0945d0b8e7a221852d9f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "768f5387bc2c4bfa87e9c16c0f31bfe1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5b655fdfd546acb896d083ce6faead": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e9c3338e38441e3ab0750395f0f2321",
              "IPY_MODEL_ebb468b66fec4f4c8c94a4cef4d23034",
              "IPY_MODEL_15d57fc0222f4f2a8e590f0e925156f3"
            ],
            "layout": "IPY_MODEL_233c8e331186427e84f0f66d7d6f1dbb"
          }
        },
        "7da2c280e6af4ff5ad350afca7d5eeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a80577c0b974e9db3546fc07f729359",
            "placeholder": "",
            "style": "IPY_MODEL_a1661f05b7a5434d9c2866715dab7722",
            "value": "1.80M/1.80M[00:00&lt;00:00,16.1MB/s]"
          }
        },
        "8a80577c0b974e9db3546fc07f729359": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b172b26363c46eb99f3385233daba95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fafb2ef234645f18eb4c349c5e9b2be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97e0215c9c2e438796a5d798153a9b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b34e45a9fce4fd58133e08165d5a746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c43d09f37c246cba59eddaabe718139": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f0743f3659a4b21a7cd87972a06b96e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1661f05b7a5434d9c2866715dab7722": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5055030578e491aa72b94d18fcb6ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8c3d2586a7464fa06585a3453850e9",
            "placeholder": "",
            "style": "IPY_MODEL_dcdc8035335f48f6bbf11a8e8e3b22c1",
            "value": "571/571[00:00&lt;00:00,17.6kB/s]"
          }
        },
        "a57342e1d4ce41578717028f77cd3dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa1782f8f91a4ad2a81c2c426ad5a2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa97ed7b1abf47768b338535d6403e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb5aeaf22bc4084bba927cb27bf5f92",
              "IPY_MODEL_f880c2ef5aec43ed8ac431c8b2fcbd8b",
              "IPY_MODEL_a5055030578e491aa72b94d18fcb6ab7"
            ],
            "layout": "IPY_MODEL_f6a3c5e91a33414b982177b431f1d2e6"
          }
        },
        "ad3d27eafbe147159d9da8f157c0e7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15262b3bf42d45b49056bcce155b3e32",
              "IPY_MODEL_0f9c895a37ac4c4684bf26078e4ee1a4",
              "IPY_MODEL_3af044402ef84e51b1035f0e0cb25fd5"
            ],
            "layout": "IPY_MODEL_66b49cbc53404fd383c85c02725024cb"
          }
        },
        "bb31570c725b40a18488052be2226499": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd21de1085e547679edcd49f07ecbea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd93ac4ea2d041219aed2a3fd362e200": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c561fbc71a89447b9c8068c43ee8f71f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5d183793ff4ca8b37ca1383c18c045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68a2adb91de441d81e20fc84837a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2d201d9b9448faaa2eb3bee8917951",
            "placeholder": "",
            "style": "IPY_MODEL_6c4ea8d4ab0945d0b8e7a221852d9f3b",
            "value": "special_tokens_map.json:100%"
          }
        },
        "da9818ea260746d0a3fc93ff4a8a95ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db45497ec31a49a998ab09edf7b3ac74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcdc8035335f48f6bbf11a8e8e3b22c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddb5aeaf22bc4084bba927cb27bf5f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c902c8b214c491d9b3fcbb6a12c60d8",
            "placeholder": "",
            "style": "IPY_MODEL_1aa74246f79d49a2a2f37ab83ceddf21",
            "value": "config.json:100%"
          }
        },
        "e95678826a0449a8a7c5a5523da54f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d68a2adb91de441d81e20fc84837a646",
              "IPY_MODEL_41e18a1da31343a0b8e3a1f74fc864bd",
              "IPY_MODEL_1e7fcd5d175740d2a919a4b25a501ab4"
            ],
            "layout": "IPY_MODEL_c561fbc71a89447b9c8068c43ee8f71f"
          }
        },
        "ebb468b66fec4f4c8c94a4cef4d23034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db45497ec31a49a998ab09edf7b3ac74",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da9818ea260746d0a3fc93ff4a8a95ae",
            "value": 967
          }
        },
        "ebedf123ec874134b0017a3fd1f4c468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a3c5e91a33414b982177b431f1d2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f880c2ef5aec43ed8ac431c8b2fcbd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd93ac4ea2d041219aed2a3fd362e200",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_563182c9072d453a8b88a9e9da223659",
            "value": 571
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
